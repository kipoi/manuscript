{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure training time for transfer learning\n",
    "\n",
    "- This notebook will show you how to quickly build a new model by pre-computing the activations of the frozen part of the network from Figure 3 and then training a simple MLP on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m_kipoi.config import get_data_dir\n",
    "ddir = get_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /users/avsec/.kipoi/models/Divergent421/downloaded/model_files/weights/2a0ae0a29337eb8106d65e1baeda85d1\n",
      "Using downloaded and verified file: /users/avsec/.kipoi/models/Divergent421/downloaded/model_files/arch/6903bcab337a6753ad010f43f208df42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/users/avsec/bin/anaconda3/envs/divergent/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/avsec/bin/anaconda3/envs/divergent/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /users/avsec/bin/anaconda3/envs/divergent/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "import kipoi\n",
    "m = kipoi.get_model(\"Divergent421\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "data/genome_data_dir (InputLayer (None, 1000, 4)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 982, 300)      23100       data/genome_data_dir[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 982, 300)      1200        convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_1 (PReLU)                  (None, 982, 300)      294600      batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 327, 300)      0           prelu_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 327, 200)      660200      maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 327, 200)      800         convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_2 (PReLU)                  (None, 327, 200)      65400       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 81, 200)       0           prelu_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 81, 200)       280200      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 81, 200)       800         convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_3 (PReLU)                  (None, 81, 200)       16200       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 20, 200)       0           prelu_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4000)          0           maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1000)          4001000     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 1000)          4000        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "prelu_4 (PReLU)                  (None, 1000)          1000        batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1000)          0           prelu_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1000)          1001000     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 1000)          4000        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "prelu_5 (PReLU)                  (None, 1000)          1000        batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1000)          0           prelu_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 421)           421421      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 421)           0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6,775,921\n",
      "Trainable params: 6,770,521\n",
      "Non-trainable params: 5,400\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run kipoi predict and measure execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command\n",
    "```bash\n",
    "kipoi predict Divergent421 \\\n",
    "  --dataloader_args='{\n",
    "\"intervals_file\":\"data/raw/tlearn/intervals_files_complete.bed3\",\n",
    "\"fasta_file\":\"data/raw/dataloader_files/shared/hg19.fa\"}' \\\n",
    "  --layer=dropout_1 \\\n",
    "  -n 10 \\\n",
    "  --output=data/processed/tlearn/bottlenecks/Divergent420/dropout_1.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 3:01:06 on Titan X (Pascal) GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m_kipoi.exp.tlearn import get_all_task_names, get_evaluated_task_names, get_heldout_names, get_multitask_names, get_exp\n",
    "from kipoi.readers import HDF5Reader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 8s, sys: 1min 44s, total: 9min 53s\n",
      "Wall time: 10min 6s\n"
     ]
    }
   ],
   "source": [
    "%time f = HDF5Reader.load(f\"{ddir}/processed/tlearn/bottlenecks/Divergent420/dropout_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes quite some time to load it. With .npy it takes ~2 min to load but takes more space. However, these activations are useful for any cell-type and need to be computed / loaded only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'preds'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16551625, 1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['preds'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = np.array(get_all_task_names())\n",
    "evaluated_tasks = np.array(get_evaluated_task_names())\n",
    "heldout_tasks = np.array(get_heldout_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENCSR000EMT', 'ENCSR000EPC', 'ENCSR452SPC', 'ENCSR714DIF',\n",
       "       'ENCSR917VCP', 'ENCSR000EOS', 'ENCSR731QLJ', 'ENCSR000EMX',\n",
       "       'ENCSR076YBB;ENCSR456KDF;ENCSR482HQE;ENCSR930AUG',\n",
       "       'ENCSR122VUW;ENCSR191EII;ENCSR320TUJ;ENCSR468ZXN;ENCSR603BXE'],\n",
       "      dtype='<U59')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENCSR000EMT'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This notebooks only shows the results for one sample\n",
    "task_name = evaluated_tasks[0]\n",
    "task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract y for each specific task\n",
    "idx_task = [(i, task) for i, task in enumerate(all_tasks) if task in evaluated_tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the training set\n",
    "test_chr = ['chr1', 'chr8', 'chr9', 'chr21']\n",
    "\n",
    "# Read the chromosomes\n",
    "chr_vec = pd.Series(f['metadata']['ranges']['chr'])\n",
    "\n",
    "is_test = chr_vec.isin(test_chr)\n",
    "\n",
    "x_train = f['preds'][0][~is_test]\n",
    "x_test = f['preds'][0][is_test]\n",
    "\n",
    "y = np.loadtxt(f\"{ddir}/raw/tlearn/labels/{task_name}.txt.gz\", dtype=bool)\n",
    "\n",
    "y_train = y[~is_test]\n",
    "y_test = y[is_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as kl\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "data/genome_data_dir (InputLayer (None, 1000, 4)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 982, 300)      23100       data/genome_data_dir[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 982, 300)      1200        convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_1 (PReLU)                  (None, 982, 300)      294600      batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 327, 300)      0           prelu_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 327, 200)      660200      maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 327, 200)      800         convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_2 (PReLU)                  (None, 327, 200)      65400       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 81, 200)       0           prelu_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 81, 200)       280200      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 81, 200)       800         convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "prelu_3 (PReLU)                  (None, 81, 200)       16200       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 20, 200)       0           prelu_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4000)          0           maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1000)          4001000     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 1000)          4000        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "prelu_4 (PReLU)                  (None, 1000)          1000        batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1000)          0           prelu_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1000)          1001000     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 1000)          4000        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "prelu_5 (PReLU)                  (None, 1000)          1000        batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1000)          0           prelu_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 421)           421421      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 421)           0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6,775,921\n",
      "Trainable params: 6,770,521\n",
      "Non-trainable params: 5,400\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same architecture after the `dropout_1` layer as before with a slight modification - the output should only be one-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/avsec/bin/anaconda3/envs/divergent/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(kl.Dense(1000, input_shape=(1000,)))\n",
    "model.add(m.model.get_layer('batchnormalization_5'))\n",
    "model.add(m.model.get_layer('prelu_5'))\n",
    "model.add(kl.Dense(1, activation='sigmoid', name='final_layer'))\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics={\"auPR\": average_precision_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialize the weights of the `dense_2` layer from before to match the transfer-learning example from Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer the weights from before\n",
    "model.layers[0].set_weights(m.model.get_layer(\"dense_2\").get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we saw that it basically takes only a single epoch to fit the model well, I'll just run it for a single epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Training the model\n",
      "Epoch 1/1\n",
      "10722640/10722640 [==============================] - 221s - loss: 0.1533   \n",
      "CPU times: user 5min 16s, sys: 1min 27s, total: 6min 43s\n",
      "Wall time: 3min 42s\n",
      "Getting the prediction\n",
      "CPU times: user 3min 17s, sys: 35.6 s, total: 3min 53s\n",
      "Wall time: 2min 11s\n",
      "auPR: 0.44433984245195457\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(f\"Batch: {i}\")\n",
    "    print(\"Training the model\")\n",
    "    %time model.fit(X_train_train, y_train_train, nb_epoch=1, batch_size=512)\n",
    "    print(\"Getting the prediction\")\n",
    "    %time y_pred = model.predict(X_valid)\n",
    "    aupr = average_precision_score(y_valid, y_pred)\n",
    "    print(f\"auPR: {aupr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "y_pred_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auPR: 0.4082066697326232\n"
     ]
    }
   ],
   "source": [
    "aupr = average_precision_score(y_test, y_pred_test)\n",
    "print(f\"test auPR: {aupr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test auPR of the other example was 0.406 which is almost the same as we got here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kipoi-manuscript-tlearn-gpu]",
   "language": "python",
   "name": "conda-env-kipoi-manuscript-tlearn-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
